{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import GridSearchCV, KFold\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.wrappers.scikit_learn import KerasClassifier\n",
    "from keras.optimizer_v1 import Adam\n",
    "from keras.optimizer_v2 import adam\n",
    "from keras.layers import Dropout\n",
    "from keras.optimizers import adam_v2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>month</th>\n",
       "      <th>day</th>\n",
       "      <th>FFMC</th>\n",
       "      <th>DMC</th>\n",
       "      <th>DC</th>\n",
       "      <th>ISI</th>\n",
       "      <th>temp</th>\n",
       "      <th>RH</th>\n",
       "      <th>wind</th>\n",
       "      <th>rain</th>\n",
       "      <th>...</th>\n",
       "      <th>monthfeb</th>\n",
       "      <th>monthjan</th>\n",
       "      <th>monthjul</th>\n",
       "      <th>monthjun</th>\n",
       "      <th>monthmar</th>\n",
       "      <th>monthmay</th>\n",
       "      <th>monthnov</th>\n",
       "      <th>monthoct</th>\n",
       "      <th>monthsep</th>\n",
       "      <th>size_category</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>mar</td>\n",
       "      <td>fri</td>\n",
       "      <td>86.2</td>\n",
       "      <td>26.2</td>\n",
       "      <td>94.3</td>\n",
       "      <td>5.1</td>\n",
       "      <td>8.2</td>\n",
       "      <td>51</td>\n",
       "      <td>6.7</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>small</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>oct</td>\n",
       "      <td>tue</td>\n",
       "      <td>90.6</td>\n",
       "      <td>35.4</td>\n",
       "      <td>669.1</td>\n",
       "      <td>6.7</td>\n",
       "      <td>18.0</td>\n",
       "      <td>33</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>small</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>oct</td>\n",
       "      <td>sat</td>\n",
       "      <td>90.6</td>\n",
       "      <td>43.7</td>\n",
       "      <td>686.9</td>\n",
       "      <td>6.7</td>\n",
       "      <td>14.6</td>\n",
       "      <td>33</td>\n",
       "      <td>1.3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>small</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>mar</td>\n",
       "      <td>fri</td>\n",
       "      <td>91.7</td>\n",
       "      <td>33.3</td>\n",
       "      <td>77.5</td>\n",
       "      <td>9.0</td>\n",
       "      <td>8.3</td>\n",
       "      <td>97</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.2</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>small</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>mar</td>\n",
       "      <td>sun</td>\n",
       "      <td>89.3</td>\n",
       "      <td>51.3</td>\n",
       "      <td>102.2</td>\n",
       "      <td>9.6</td>\n",
       "      <td>11.4</td>\n",
       "      <td>99</td>\n",
       "      <td>1.8</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>small</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  month  day  FFMC   DMC     DC  ISI  temp  RH  wind  rain  ...  monthfeb  \\\n",
       "0   mar  fri  86.2  26.2   94.3  5.1   8.2  51   6.7   0.0  ...         0   \n",
       "1   oct  tue  90.6  35.4  669.1  6.7  18.0  33   0.9   0.0  ...         0   \n",
       "2   oct  sat  90.6  43.7  686.9  6.7  14.6  33   1.3   0.0  ...         0   \n",
       "3   mar  fri  91.7  33.3   77.5  9.0   8.3  97   4.0   0.2  ...         0   \n",
       "4   mar  sun  89.3  51.3  102.2  9.6  11.4  99   1.8   0.0  ...         0   \n",
       "\n",
       "   monthjan  monthjul  monthjun  monthmar  monthmay  monthnov  monthoct  \\\n",
       "0         0         0         0         1         0         0         0   \n",
       "1         0         0         0         0         0         0         1   \n",
       "2         0         0         0         0         0         0         1   \n",
       "3         0         0         0         1         0         0         0   \n",
       "4         0         0         0         1         0         0         0   \n",
       "\n",
       "   monthsep  size_category  \n",
       "0         0          small  \n",
       "1         0          small  \n",
       "2         0          small  \n",
       "3         0          small  \n",
       "4         0          small  \n",
       "\n",
       "[5 rows x 31 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv(\"forestfires.csv\")\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['month', 'day', 'FFMC', 'DMC', 'DC', 'ISI', 'temp', 'RH', 'wind',\n",
       "       'rain', 'area', 'dayfri', 'daymon', 'daysat', 'daysun', 'daythu',\n",
       "       'daytue', 'daywed', 'monthapr', 'monthaug', 'monthdec', 'monthfeb',\n",
       "       'monthjan', 'monthjul', 'monthjun', 'monthmar', 'monthmay', 'monthnov',\n",
       "       'monthoct', 'monthsep', 'size_category'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import preprocessing\n",
    "label_encoder = preprocessing.LabelEncoder()\n",
    "data['month']= label_encoder.fit_transform(data['month'])\n",
    "data['day']= label_encoder.fit_transform(data['day'])\n",
    "data['size_category']= label_encoder.fit_transform(data['size_category'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>month</th>\n",
       "      <th>day</th>\n",
       "      <th>FFMC</th>\n",
       "      <th>DMC</th>\n",
       "      <th>DC</th>\n",
       "      <th>ISI</th>\n",
       "      <th>temp</th>\n",
       "      <th>RH</th>\n",
       "      <th>wind</th>\n",
       "      <th>rain</th>\n",
       "      <th>...</th>\n",
       "      <th>monthfeb</th>\n",
       "      <th>monthjan</th>\n",
       "      <th>monthjul</th>\n",
       "      <th>monthjun</th>\n",
       "      <th>monthmar</th>\n",
       "      <th>monthmay</th>\n",
       "      <th>monthnov</th>\n",
       "      <th>monthoct</th>\n",
       "      <th>monthsep</th>\n",
       "      <th>size_category</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>86.2</td>\n",
       "      <td>26.2</td>\n",
       "      <td>94.3</td>\n",
       "      <td>5.1</td>\n",
       "      <td>8.2</td>\n",
       "      <td>51</td>\n",
       "      <td>6.7</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10</td>\n",
       "      <td>5</td>\n",
       "      <td>90.6</td>\n",
       "      <td>35.4</td>\n",
       "      <td>669.1</td>\n",
       "      <td>6.7</td>\n",
       "      <td>18.0</td>\n",
       "      <td>33</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10</td>\n",
       "      <td>2</td>\n",
       "      <td>90.6</td>\n",
       "      <td>43.7</td>\n",
       "      <td>686.9</td>\n",
       "      <td>6.7</td>\n",
       "      <td>14.6</td>\n",
       "      <td>33</td>\n",
       "      <td>1.3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>91.7</td>\n",
       "      <td>33.3</td>\n",
       "      <td>77.5</td>\n",
       "      <td>9.0</td>\n",
       "      <td>8.3</td>\n",
       "      <td>97</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.2</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7</td>\n",
       "      <td>3</td>\n",
       "      <td>89.3</td>\n",
       "      <td>51.3</td>\n",
       "      <td>102.2</td>\n",
       "      <td>9.6</td>\n",
       "      <td>11.4</td>\n",
       "      <td>99</td>\n",
       "      <td>1.8</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>512</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>81.6</td>\n",
       "      <td>56.7</td>\n",
       "      <td>665.6</td>\n",
       "      <td>1.9</td>\n",
       "      <td>27.8</td>\n",
       "      <td>32</td>\n",
       "      <td>2.7</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>513</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>81.6</td>\n",
       "      <td>56.7</td>\n",
       "      <td>665.6</td>\n",
       "      <td>1.9</td>\n",
       "      <td>21.9</td>\n",
       "      <td>71</td>\n",
       "      <td>5.8</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>514</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>81.6</td>\n",
       "      <td>56.7</td>\n",
       "      <td>665.6</td>\n",
       "      <td>1.9</td>\n",
       "      <td>21.2</td>\n",
       "      <td>70</td>\n",
       "      <td>6.7</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>515</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>94.4</td>\n",
       "      <td>146.0</td>\n",
       "      <td>614.7</td>\n",
       "      <td>11.3</td>\n",
       "      <td>25.6</td>\n",
       "      <td>42</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>516</th>\n",
       "      <td>9</td>\n",
       "      <td>5</td>\n",
       "      <td>79.5</td>\n",
       "      <td>3.0</td>\n",
       "      <td>106.7</td>\n",
       "      <td>1.1</td>\n",
       "      <td>11.8</td>\n",
       "      <td>31</td>\n",
       "      <td>4.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>517 rows × 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     month  day  FFMC    DMC     DC   ISI  temp  RH  wind  rain  ...  \\\n",
       "0        7    0  86.2   26.2   94.3   5.1   8.2  51   6.7   0.0  ...   \n",
       "1       10    5  90.6   35.4  669.1   6.7  18.0  33   0.9   0.0  ...   \n",
       "2       10    2  90.6   43.7  686.9   6.7  14.6  33   1.3   0.0  ...   \n",
       "3        7    0  91.7   33.3   77.5   9.0   8.3  97   4.0   0.2  ...   \n",
       "4        7    3  89.3   51.3  102.2   9.6  11.4  99   1.8   0.0  ...   \n",
       "..     ...  ...   ...    ...    ...   ...   ...  ..   ...   ...  ...   \n",
       "512      1    3  81.6   56.7  665.6   1.9  27.8  32   2.7   0.0  ...   \n",
       "513      1    3  81.6   56.7  665.6   1.9  21.9  71   5.8   0.0  ...   \n",
       "514      1    3  81.6   56.7  665.6   1.9  21.2  70   6.7   0.0  ...   \n",
       "515      1    2  94.4  146.0  614.7  11.3  25.6  42   4.0   0.0  ...   \n",
       "516      9    5  79.5    3.0  106.7   1.1  11.8  31   4.5   0.0  ...   \n",
       "\n",
       "     monthfeb  monthjan  monthjul  monthjun  monthmar  monthmay  monthnov  \\\n",
       "0           0         0         0         0         1         0         0   \n",
       "1           0         0         0         0         0         0         0   \n",
       "2           0         0         0         0         0         0         0   \n",
       "3           0         0         0         0         1         0         0   \n",
       "4           0         0         0         0         1         0         0   \n",
       "..        ...       ...       ...       ...       ...       ...       ...   \n",
       "512         0         0         0         0         0         0         0   \n",
       "513         0         0         0         0         0         0         0   \n",
       "514         0         0         0         0         0         0         0   \n",
       "515         0         0         0         0         0         0         0   \n",
       "516         0         0         0         0         0         0         1   \n",
       "\n",
       "     monthoct  monthsep  size_category  \n",
       "0           0         0              1  \n",
       "1           1         0              1  \n",
       "2           1         0              1  \n",
       "3           0         0              1  \n",
       "4           0         0              1  \n",
       "..        ...       ...            ...  \n",
       "512         0         0              0  \n",
       "513         0         0              0  \n",
       "514         0         0              0  \n",
       "515         0         0              1  \n",
       "516         0         0              1  \n",
       "\n",
       "[517 rows x 31 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = data.iloc[:,:-1]\n",
    "y = data.iloc[:,-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed = 7\n",
    "np.random.seed(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Dense(12, input_dim=30,  kernel_initializer='uniform', activation='relu'))\n",
    "model.add(Dense(8,  kernel_initializer='uniform', activation='relu'))\n",
    "model.add(Dense(1,  kernel_initializer='uniform', activation='sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/150\n",
      "35/35 [==============================] - 37s 35ms/step - loss: 0.6739 - accuracy: 0.5755 - val_loss: 0.6373 - val_accuracy: 0.6784\n",
      "Epoch 2/150\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 0.5624 - accuracy: 0.7565 - val_loss: 0.6588 - val_accuracy: 0.6784\n",
      "Epoch 3/150\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 0.5244 - accuracy: 0.7806 - val_loss: 0.6282 - val_accuracy: 0.6842\n",
      "Epoch 4/150\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 0.5628 - accuracy: 0.7576 - val_loss: 0.6692 - val_accuracy: 0.6842\n",
      "Epoch 5/150\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 0.5326 - accuracy: 0.7627 - val_loss: 0.5973 - val_accuracy: 0.6959\n",
      "Epoch 6/150\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 0.4980 - accuracy: 0.7695 - val_loss: 0.5443 - val_accuracy: 0.7251\n",
      "Epoch 7/150\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 0.4688 - accuracy: 0.7968 - val_loss: 0.5385 - val_accuracy: 0.7427\n",
      "Epoch 8/150\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 0.4158 - accuracy: 0.8150 - val_loss: 0.4685 - val_accuracy: 0.7895\n",
      "Epoch 9/150\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 0.3891 - accuracy: 0.8463 - val_loss: 0.4463 - val_accuracy: 0.8012\n",
      "Epoch 10/150\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 0.3100 - accuracy: 0.8631 - val_loss: 0.3292 - val_accuracy: 0.9064\n",
      "Epoch 11/150\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 0.2625 - accuracy: 0.9033 - val_loss: 0.2753 - val_accuracy: 0.8713\n",
      "Epoch 12/150\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 0.2362 - accuracy: 0.9112 - val_loss: 0.4026 - val_accuracy: 0.8129\n",
      "Epoch 13/150\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 0.1633 - accuracy: 0.9237 - val_loss: 0.2087 - val_accuracy: 0.9240\n",
      "Epoch 14/150\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 0.1608 - accuracy: 0.9437 - val_loss: 0.2228 - val_accuracy: 0.8713\n",
      "Epoch 15/150\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 0.1305 - accuracy: 0.9573 - val_loss: 0.1664 - val_accuracy: 0.9064\n",
      "Epoch 16/150\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 0.1168 - accuracy: 0.9489 - val_loss: 0.1480 - val_accuracy: 0.9766\n",
      "Epoch 17/150\n",
      "35/35 [==============================] - 0s 5ms/step - loss: 0.0855 - accuracy: 0.9839 - val_loss: 0.1411 - val_accuracy: 0.9181\n",
      "Epoch 18/150\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 0.1100 - accuracy: 0.9619 - val_loss: 0.2684 - val_accuracy: 0.8889\n",
      "Epoch 19/150\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 0.1029 - accuracy: 0.9698 - val_loss: 0.2148 - val_accuracy: 0.9064\n",
      "Epoch 20/150\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 0.1141 - accuracy: 0.9522 - val_loss: 0.1076 - val_accuracy: 0.9766\n",
      "Epoch 21/150\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 0.0524 - accuracy: 0.9836 - val_loss: 0.2259 - val_accuracy: 0.9357\n",
      "Epoch 22/150\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 0.0908 - accuracy: 0.9550 - val_loss: 0.0971 - val_accuracy: 0.9766\n",
      "Epoch 23/150\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 0.0542 - accuracy: 0.9891 - val_loss: 0.1972 - val_accuracy: 0.9357\n",
      "Epoch 24/150\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 0.0966 - accuracy: 0.9641 - val_loss: 0.1136 - val_accuracy: 0.9474\n",
      "Epoch 25/150\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 0.0358 - accuracy: 0.9901 - val_loss: 0.1354 - val_accuracy: 0.9591\n",
      "Epoch 26/150\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 0.0503 - accuracy: 0.9901 - val_loss: 0.0862 - val_accuracy: 0.9825\n",
      "Epoch 27/150\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 0.0456 - accuracy: 0.9863 - val_loss: 0.0971 - val_accuracy: 0.9591\n",
      "Epoch 28/150\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 0.0375 - accuracy: 0.9963 - val_loss: 0.0815 - val_accuracy: 0.9825\n",
      "Epoch 29/150\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 0.0286 - accuracy: 0.9952 - val_loss: 0.0916 - val_accuracy: 0.9649\n",
      "Epoch 30/150\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 0.0252 - accuracy: 0.9936 - val_loss: 0.0805 - val_accuracy: 0.9883\n",
      "Epoch 31/150\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 0.0413 - accuracy: 0.9787 - val_loss: 0.1171 - val_accuracy: 0.9415\n",
      "Epoch 32/150\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 0.0442 - accuracy: 0.9840 - val_loss: 0.0750 - val_accuracy: 0.9708\n",
      "Epoch 33/150\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 0.0414 - accuracy: 0.9831 - val_loss: 0.1547 - val_accuracy: 0.9357\n",
      "Epoch 34/150\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 0.0760 - accuracy: 0.9525 - val_loss: 0.0743 - val_accuracy: 0.9883\n",
      "Epoch 35/150\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 0.0253 - accuracy: 0.9889 - val_loss: 0.0709 - val_accuracy: 0.9825\n",
      "Epoch 36/150\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 0.0273 - accuracy: 0.9946 - val_loss: 0.0747 - val_accuracy: 0.9825\n",
      "Epoch 37/150\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 0.0464 - accuracy: 0.9849 - val_loss: 0.1102 - val_accuracy: 0.9532\n",
      "Epoch 38/150\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 0.0248 - accuracy: 0.9932 - val_loss: 0.1580 - val_accuracy: 0.9298\n",
      "Epoch 39/150\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 0.0614 - accuracy: 0.9718 - val_loss: 0.2094 - val_accuracy: 0.9357\n",
      "Epoch 40/150\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 0.0542 - accuracy: 0.9706 - val_loss: 0.0963 - val_accuracy: 0.9532\n",
      "Epoch 41/150\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 0.0333 - accuracy: 0.9966 - val_loss: 0.0896 - val_accuracy: 0.9708\n",
      "Epoch 42/150\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 0.0396 - accuracy: 0.9848 - val_loss: 0.0691 - val_accuracy: 0.9766\n",
      "Epoch 43/150\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 0.0569 - accuracy: 0.9728 - val_loss: 0.1336 - val_accuracy: 0.9415\n",
      "Epoch 44/150\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 0.0420 - accuracy: 0.9794 - val_loss: 0.2224 - val_accuracy: 0.9123\n",
      "Epoch 45/150\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 0.0642 - accuracy: 0.9743 - val_loss: 0.1010 - val_accuracy: 0.9649\n",
      "Epoch 46/150\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 0.0292 - accuracy: 0.9860 - val_loss: 0.0760 - val_accuracy: 0.9708\n",
      "Epoch 47/150\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 0.0268 - accuracy: 0.9908 - val_loss: 0.0808 - val_accuracy: 0.9591\n",
      "Epoch 48/150\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 0.0205 - accuracy: 0.9967 - val_loss: 0.0793 - val_accuracy: 0.9825\n",
      "Epoch 49/150\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 0.0254 - accuracy: 0.9900 - val_loss: 0.1731 - val_accuracy: 0.9357\n",
      "Epoch 50/150\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 0.0499 - accuracy: 0.9809 - val_loss: 0.2057 - val_accuracy: 0.9357\n",
      "Epoch 51/150\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 0.0431 - accuracy: 0.9817 - val_loss: 0.1200 - val_accuracy: 0.9415\n",
      "Epoch 52/150\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 0.0310 - accuracy: 0.9755 - val_loss: 0.0690 - val_accuracy: 0.9708\n",
      "Epoch 53/150\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 0.0147 - accuracy: 0.9982 - val_loss: 0.0767 - val_accuracy: 0.9649\n",
      "Epoch 54/150\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 0.0267 - accuracy: 0.9942 - val_loss: 0.0713 - val_accuracy: 0.9825\n",
      "Epoch 55/150\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 0.0171 - accuracy: 0.9920 - val_loss: 0.0930 - val_accuracy: 0.9415\n",
      "Epoch 56/150\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 0.0563 - accuracy: 0.9781 - val_loss: 0.0741 - val_accuracy: 0.9649\n",
      "Epoch 57/150\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 0.0184 - accuracy: 0.9914 - val_loss: 0.1082 - val_accuracy: 0.9415\n",
      "Epoch 58/150\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 0.0173 - accuracy: 0.9975 - val_loss: 0.0738 - val_accuracy: 0.9825\n",
      "Epoch 59/150\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 0.0217 - accuracy: 0.9942 - val_loss: 0.1111 - val_accuracy: 0.9415\n",
      "Epoch 60/150\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 0.0596 - accuracy: 0.9652 - val_loss: 0.2176 - val_accuracy: 0.9298\n",
      "Epoch 61/150\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 0.0817 - accuracy: 0.9717 - val_loss: 0.0749 - val_accuracy: 0.9649\n",
      "Epoch 62/150\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 0.0297 - accuracy: 0.9922 - val_loss: 0.0725 - val_accuracy: 0.9708\n",
      "Epoch 63/150\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 0.0178 - accuracy: 0.9932 - val_loss: 0.0722 - val_accuracy: 0.9825\n",
      "Epoch 64/150\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 0.0214 - accuracy: 0.9908 - val_loss: 0.0746 - val_accuracy: 0.9766\n",
      "Epoch 65/150\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 0.0202 - accuracy: 0.9914 - val_loss: 0.0861 - val_accuracy: 0.9766\n",
      "Epoch 66/150\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 0.0243 - accuracy: 0.9969 - val_loss: 0.0723 - val_accuracy: 0.9708\n",
      "Epoch 67/150\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 0.0497 - accuracy: 0.9864 - val_loss: 0.0773 - val_accuracy: 0.9708\n",
      "Epoch 68/150\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 0.0165 - accuracy: 0.9930 - val_loss: 0.0746 - val_accuracy: 0.9708\n",
      "Epoch 69/150\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 0.0102 - accuracy: 0.9992 - val_loss: 0.2126 - val_accuracy: 0.9357\n",
      "Epoch 70/150\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 0.0825 - accuracy: 0.9734 - val_loss: 0.0744 - val_accuracy: 0.9708\n",
      "Epoch 71/150\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 0.0246 - accuracy: 0.9887 - val_loss: 0.2649 - val_accuracy: 0.9123\n",
      "Epoch 72/150\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 0.0343 - accuracy: 0.9855 - val_loss: 0.0743 - val_accuracy: 0.9766\n",
      "Epoch 73/150\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 0.0405 - accuracy: 0.9845 - val_loss: 0.0863 - val_accuracy: 0.9825\n",
      "Epoch 74/150\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 0.0221 - accuracy: 0.9932 - val_loss: 0.0721 - val_accuracy: 0.9766\n",
      "Epoch 75/150\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 0.0076 - accuracy: 0.9998 - val_loss: 0.0739 - val_accuracy: 0.9825\n",
      "Epoch 76/150\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 0.0188 - accuracy: 0.9952 - val_loss: 0.0812 - val_accuracy: 0.9591\n",
      "Epoch 77/150\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 0.0116 - accuracy: 0.9980 - val_loss: 0.1135 - val_accuracy: 0.9415\n",
      "Epoch 78/150\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 0.0161 - accuracy: 0.9938 - val_loss: 0.3592 - val_accuracy: 0.8947\n",
      "Epoch 79/150\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 0.0290 - accuracy: 0.9871 - val_loss: 0.0765 - val_accuracy: 0.9766\n",
      "Epoch 80/150\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 0.0233 - accuracy: 0.9826 - val_loss: 0.0793 - val_accuracy: 0.9649\n",
      "Epoch 81/150\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 0.0082 - accuracy: 0.9954 - val_loss: 0.1354 - val_accuracy: 0.9415\n",
      "Epoch 82/150\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 0.0114 - accuracy: 0.9966 - val_loss: 0.0816 - val_accuracy: 0.9591\n",
      "Epoch 83/150\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 0.0460 - accuracy: 0.9777 - val_loss: 0.1051 - val_accuracy: 0.9649\n",
      "Epoch 84/150\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 0.0096 - accuracy: 0.9978 - val_loss: 0.1061 - val_accuracy: 0.9649\n",
      "Epoch 85/150\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 0.0173 - accuracy: 0.9928 - val_loss: 0.0795 - val_accuracy: 0.9825\n",
      "Epoch 86/150\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 0.0077 - accuracy: 0.9990 - val_loss: 0.0737 - val_accuracy: 0.9708\n",
      "Epoch 87/150\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 0.0180 - accuracy: 0.9959 - val_loss: 0.1910 - val_accuracy: 0.9357\n",
      "Epoch 88/150\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 0.0250 - accuracy: 0.9978 - val_loss: 0.0787 - val_accuracy: 0.9708\n",
      "Epoch 89/150\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 0.0132 - accuracy: 0.9957 - val_loss: 0.1580 - val_accuracy: 0.9532\n",
      "Epoch 90/150\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 0.0236 - accuracy: 0.9845 - val_loss: 0.0858 - val_accuracy: 0.9591\n",
      "Epoch 91/150\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 0.0107 - accuracy: 0.9989 - val_loss: 0.0784 - val_accuracy: 0.9708\n",
      "Epoch 92/150\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 0.0199 - accuracy: 0.9900 - val_loss: 0.1188 - val_accuracy: 0.9415\n",
      "Epoch 93/150\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 0.0150 - accuracy: 0.9951 - val_loss: 0.1268 - val_accuracy: 0.9415\n",
      "Epoch 94/150\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 0.0088 - accuracy: 0.9994 - val_loss: 0.0867 - val_accuracy: 0.9591\n",
      "Epoch 95/150\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 0.0143 - accuracy: 0.9935 - val_loss: 0.1034 - val_accuracy: 0.9708\n",
      "Epoch 96/150\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 0.0510 - accuracy: 0.9794 - val_loss: 0.0836 - val_accuracy: 0.9708\n",
      "Epoch 97/150\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 0.0276 - accuracy: 0.9943 - val_loss: 0.1056 - val_accuracy: 0.9415\n",
      "Epoch 98/150\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 0.0097 - accuracy: 0.9970 - val_loss: 0.0847 - val_accuracy: 0.9591\n",
      "Epoch 99/150\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 0.0090 - accuracy: 0.9987 - val_loss: 0.1558 - val_accuracy: 0.9357\n",
      "Epoch 100/150\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 0.0096 - accuracy: 0.9996 - val_loss: 0.1194 - val_accuracy: 0.9591\n",
      "Epoch 101/150\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 0.0348 - accuracy: 0.9806 - val_loss: 0.0831 - val_accuracy: 0.9708\n",
      "Epoch 102/150\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 0.0267 - accuracy: 0.9834 - val_loss: 0.0854 - val_accuracy: 0.9708\n",
      "Epoch 103/150\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 0.0217 - accuracy: 0.9907 - val_loss: 0.0892 - val_accuracy: 0.9649\n",
      "Epoch 104/150\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 0.0204 - accuracy: 0.9892 - val_loss: 0.0923 - val_accuracy: 0.9532\n",
      "Epoch 105/150\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 0.0135 - accuracy: 0.9975 - val_loss: 0.0835 - val_accuracy: 0.9708\n",
      "Epoch 106/150\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 0.0539 - accuracy: 0.9760 - val_loss: 0.2036 - val_accuracy: 0.9240\n",
      "Epoch 107/150\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 0.0132 - accuracy: 0.9934 - val_loss: 0.0917 - val_accuracy: 0.9766\n",
      "Epoch 108/150\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 0.0189 - accuracy: 0.9950 - val_loss: 0.1455 - val_accuracy: 0.9357\n",
      "Epoch 109/150\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 0.0328 - accuracy: 0.9928 - val_loss: 0.1276 - val_accuracy: 0.9415\n",
      "Epoch 110/150\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 0.0384 - accuracy: 0.9871 - val_loss: 0.0914 - val_accuracy: 0.9649\n",
      "Epoch 111/150\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 0.0142 - accuracy: 0.9972 - val_loss: 0.0945 - val_accuracy: 0.9766\n",
      "Epoch 112/150\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 0.0168 - accuracy: 0.9930 - val_loss: 0.0953 - val_accuracy: 0.9591\n",
      "Epoch 113/150\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 0.0216 - accuracy: 0.9948 - val_loss: 0.4212 - val_accuracy: 0.8830\n",
      "Epoch 114/150\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 0.1277 - accuracy: 0.9630 - val_loss: 0.0745 - val_accuracy: 0.9708\n",
      "Epoch 115/150\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 0.0182 - accuracy: 0.9923 - val_loss: 0.1033 - val_accuracy: 0.9649\n",
      "Epoch 116/150\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 0.0230 - accuracy: 0.9831 - val_loss: 0.1450 - val_accuracy: 0.9532\n",
      "Epoch 117/150\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 0.0141 - accuracy: 0.9908 - val_loss: 0.0841 - val_accuracy: 0.9708\n",
      "Epoch 118/150\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 0.0119 - accuracy: 0.9958 - val_loss: 0.2888 - val_accuracy: 0.9181\n",
      "Epoch 119/150\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 0.0657 - accuracy: 0.9828 - val_loss: 0.2927 - val_accuracy: 0.9181\n",
      "Epoch 120/150\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 0.0645 - accuracy: 0.9705 - val_loss: 0.0854 - val_accuracy: 0.9708\n",
      "Epoch 121/150\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 0.0303 - accuracy: 0.9909 - val_loss: 0.1956 - val_accuracy: 0.9474\n",
      "Epoch 122/150\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 0.0193 - accuracy: 0.9882 - val_loss: 0.0785 - val_accuracy: 0.9708\n",
      "Epoch 123/150\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 0.0190 - accuracy: 0.9938 - val_loss: 0.0985 - val_accuracy: 0.9474\n",
      "Epoch 124/150\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 0.0052 - accuracy: 0.9994 - val_loss: 0.1285 - val_accuracy: 0.9591\n",
      "Epoch 125/150\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 0.0102 - accuracy: 1.0000 - val_loss: 0.0992 - val_accuracy: 0.9591\n",
      "Epoch 126/150\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 0.0227 - accuracy: 0.9911 - val_loss: 0.0950 - val_accuracy: 0.9708\n",
      "Epoch 127/150\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 0.0153 - accuracy: 0.9971 - val_loss: 0.0844 - val_accuracy: 0.9708\n",
      "Epoch 128/150\n",
      "35/35 [==============================] - 0s 5ms/step - loss: 0.0156 - accuracy: 0.9864 - val_loss: 0.0833 - val_accuracy: 0.9708\n",
      "Epoch 129/150\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 0.0088 - accuracy: 0.9966 - val_loss: 0.0887 - val_accuracy: 0.9649\n",
      "Epoch 130/150\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 0.0086 - accuracy: 0.9981 - val_loss: 0.0962 - val_accuracy: 0.9708\n",
      "Epoch 131/150\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 0.0197 - accuracy: 0.9950 - val_loss: 0.1449 - val_accuracy: 0.9357\n",
      "Epoch 132/150\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 0.0111 - accuracy: 0.9952 - val_loss: 0.1601 - val_accuracy: 0.9298\n",
      "Epoch 133/150\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 0.0124 - accuracy: 0.9965 - val_loss: 0.0813 - val_accuracy: 0.9766\n",
      "Epoch 134/150\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 0.0072 - accuracy: 0.9995 - val_loss: 0.1165 - val_accuracy: 0.9591\n",
      "Epoch 135/150\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 0.0117 - accuracy: 0.9978 - val_loss: 0.0860 - val_accuracy: 0.9708\n",
      "Epoch 136/150\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 0.0302 - accuracy: 0.9865 - val_loss: 0.0925 - val_accuracy: 0.9708\n",
      "Epoch 137/150\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 0.0136 - accuracy: 0.9942 - val_loss: 0.0971 - val_accuracy: 0.9532\n",
      "Epoch 138/150\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 0.0077 - accuracy: 0.9977 - val_loss: 0.0945 - val_accuracy: 0.9591\n",
      "Epoch 139/150\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 0.0282 - accuracy: 0.9786 - val_loss: 0.0830 - val_accuracy: 0.9708\n",
      "Epoch 140/150\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 0.0289 - accuracy: 0.9912 - val_loss: 0.0812 - val_accuracy: 0.9708\n",
      "Epoch 141/150\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 0.0143 - accuracy: 0.9956 - val_loss: 0.0984 - val_accuracy: 0.9532\n",
      "Epoch 142/150\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 0.0088 - accuracy: 0.9968 - val_loss: 0.0808 - val_accuracy: 0.9708\n",
      "Epoch 143/150\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 0.0107 - accuracy: 0.9956 - val_loss: 0.1023 - val_accuracy: 0.9474\n",
      "Epoch 144/150\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 0.0238 - accuracy: 0.9876 - val_loss: 0.0884 - val_accuracy: 0.9708\n",
      "Epoch 145/150\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 0.0136 - accuracy: 0.9947 - val_loss: 0.0922 - val_accuracy: 0.9591\n",
      "Epoch 146/150\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 0.0058 - accuracy: 0.9993 - val_loss: 0.0955 - val_accuracy: 0.9708\n",
      "Epoch 147/150\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 0.0302 - accuracy: 0.9839 - val_loss: 0.1036 - val_accuracy: 0.9532\n",
      "Epoch 148/150\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 0.0042 - accuracy: 0.9998 - val_loss: 0.1055 - val_accuracy: 0.9591\n",
      "Epoch 149/150\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 0.0269 - accuracy: 0.9923 - val_loss: 0.1099 - val_accuracy: 0.9474\n",
      "Epoch 150/150\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 0.0351 - accuracy: 0.9952 - val_loss: 0.0892 - val_accuracy: 0.9708\n"
     ]
    }
   ],
   "source": [
    "history= model.fit(x, y, validation_split=0.33, epochs=150, batch_size=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17/17 [==============================] - 0s 2ms/step - loss: 0.0344 - accuracy: 0.9884\n",
      "accuracy: 98.84%\n"
     ]
    }
   ],
   "source": [
    "scores = model.evaluate(x, y)\n",
    "print(\"%s: %.2f%%\" % (model.metrics_names[1], scores[1]*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['loss', 'accuracy', 'val_loss', 'val_accuracy'])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "history.history.keys()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = StandardScaler()\n",
    "a.fit(x)\n",
    "X_standardized = a.transform(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>20</th>\n",
       "      <th>21</th>\n",
       "      <th>22</th>\n",
       "      <th>23</th>\n",
       "      <th>24</th>\n",
       "      <th>25</th>\n",
       "      <th>26</th>\n",
       "      <th>27</th>\n",
       "      <th>28</th>\n",
       "      <th>29</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>5.170000e+02</td>\n",
       "      <td>5.170000e+02</td>\n",
       "      <td>5.170000e+02</td>\n",
       "      <td>5.170000e+02</td>\n",
       "      <td>5.170000e+02</td>\n",
       "      <td>5.170000e+02</td>\n",
       "      <td>5.170000e+02</td>\n",
       "      <td>5.170000e+02</td>\n",
       "      <td>5.170000e+02</td>\n",
       "      <td>5.170000e+02</td>\n",
       "      <td>...</td>\n",
       "      <td>5.170000e+02</td>\n",
       "      <td>5.170000e+02</td>\n",
       "      <td>5.170000e+02</td>\n",
       "      <td>5.170000e+02</td>\n",
       "      <td>5.170000e+02</td>\n",
       "      <td>5.170000e+02</td>\n",
       "      <td>5.170000e+02</td>\n",
       "      <td>5.170000e+02</td>\n",
       "      <td>5.170000e+02</td>\n",
       "      <td>5.170000e+02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>-4.874674e-17</td>\n",
       "      <td>5.110891e-17</td>\n",
       "      <td>-1.754024e-15</td>\n",
       "      <td>3.070830e-16</td>\n",
       "      <td>7.387171e-17</td>\n",
       "      <td>-3.865380e-17</td>\n",
       "      <td>2.005703e-16</td>\n",
       "      <td>3.362881e-16</td>\n",
       "      <td>-2.676776e-16</td>\n",
       "      <td>-2.841054e-16</td>\n",
       "      <td>...</td>\n",
       "      <td>7.179943e-16</td>\n",
       "      <td>-1.933764e-16</td>\n",
       "      <td>-2.260174e-17</td>\n",
       "      <td>1.352883e-17</td>\n",
       "      <td>1.169277e-16</td>\n",
       "      <td>2.265542e-16</td>\n",
       "      <td>-2.596515e-16</td>\n",
       "      <td>1.443075e-16</td>\n",
       "      <td>6.253326e-16</td>\n",
       "      <td>4.024290e-16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>1.000969e+00</td>\n",
       "      <td>1.000969e+00</td>\n",
       "      <td>1.000969e+00</td>\n",
       "      <td>1.000969e+00</td>\n",
       "      <td>1.000969e+00</td>\n",
       "      <td>1.000969e+00</td>\n",
       "      <td>1.000969e+00</td>\n",
       "      <td>1.000969e+00</td>\n",
       "      <td>1.000969e+00</td>\n",
       "      <td>1.000969e+00</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000969e+00</td>\n",
       "      <td>1.000969e+00</td>\n",
       "      <td>1.000969e+00</td>\n",
       "      <td>1.000969e+00</td>\n",
       "      <td>1.000969e+00</td>\n",
       "      <td>1.000969e+00</td>\n",
       "      <td>1.000969e+00</td>\n",
       "      <td>1.000969e+00</td>\n",
       "      <td>1.000969e+00</td>\n",
       "      <td>1.000969e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>-1.317959e+00</td>\n",
       "      <td>-1.423121e+00</td>\n",
       "      <td>-1.304582e+01</td>\n",
       "      <td>-1.715608e+00</td>\n",
       "      <td>-2.179108e+00</td>\n",
       "      <td>-1.980578e+00</td>\n",
       "      <td>-2.876943e+00</td>\n",
       "      <td>-1.796637e+00</td>\n",
       "      <td>-2.021098e+00</td>\n",
       "      <td>-7.326831e-02</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.331035e-01</td>\n",
       "      <td>-2.006027e-01</td>\n",
       "      <td>-6.231770e-02</td>\n",
       "      <td>-2.568645e-01</td>\n",
       "      <td>-1.843909e-01</td>\n",
       "      <td>-3.415123e-01</td>\n",
       "      <td>-6.231770e-02</td>\n",
       "      <td>-4.402255e-02</td>\n",
       "      <td>-1.728597e-01</td>\n",
       "      <td>-7.060812e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>-1.089076e+00</td>\n",
       "      <td>-9.031536e-01</td>\n",
       "      <td>-8.063453e-02</td>\n",
       "      <td>-6.606652e-01</td>\n",
       "      <td>-4.448281e-01</td>\n",
       "      <td>-5.535954e-01</td>\n",
       "      <td>-5.842379e-01</td>\n",
       "      <td>-6.924563e-01</td>\n",
       "      <td>-7.361236e-01</td>\n",
       "      <td>-7.326831e-02</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.331035e-01</td>\n",
       "      <td>-2.006027e-01</td>\n",
       "      <td>-6.231770e-02</td>\n",
       "      <td>-2.568645e-01</td>\n",
       "      <td>-1.843909e-01</td>\n",
       "      <td>-3.415123e-01</td>\n",
       "      <td>-6.231770e-02</td>\n",
       "      <td>-4.402255e-02</td>\n",
       "      <td>-1.728597e-01</td>\n",
       "      <td>-7.060812e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>5.533922e-02</td>\n",
       "      <td>1.367805e-01</td>\n",
       "      <td>1.732292e-01</td>\n",
       "      <td>-4.020255e-02</td>\n",
       "      <td>4.691190e-01</td>\n",
       "      <td>-1.364774e-01</td>\n",
       "      <td>7.082076e-02</td>\n",
       "      <td>-1.403660e-01</td>\n",
       "      <td>-9.833712e-03</td>\n",
       "      <td>-7.326831e-02</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.331035e-01</td>\n",
       "      <td>-2.006027e-01</td>\n",
       "      <td>-6.231770e-02</td>\n",
       "      <td>-2.568645e-01</td>\n",
       "      <td>-1.843909e-01</td>\n",
       "      <td>-3.415123e-01</td>\n",
       "      <td>-6.231770e-02</td>\n",
       "      <td>-4.402255e-02</td>\n",
       "      <td>-1.728597e-01</td>\n",
       "      <td>-7.060812e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>1.199754e+00</td>\n",
       "      <td>6.567476e-01</td>\n",
       "      <td>4.089598e-01</td>\n",
       "      <td>4.927389e-01</td>\n",
       "      <td>6.696628e-01</td>\n",
       "      <td>3.904086e-01</td>\n",
       "      <td>6.741643e-01</td>\n",
       "      <td>5.344111e-01</td>\n",
       "      <td>4.929823e-01</td>\n",
       "      <td>-7.326831e-02</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.331035e-01</td>\n",
       "      <td>-2.006027e-01</td>\n",
       "      <td>-6.231770e-02</td>\n",
       "      <td>-2.568645e-01</td>\n",
       "      <td>-1.843909e-01</td>\n",
       "      <td>-3.415123e-01</td>\n",
       "      <td>-6.231770e-02</td>\n",
       "      <td>-4.402255e-02</td>\n",
       "      <td>-1.728597e-01</td>\n",
       "      <td>1.416268e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1.199754e+00</td>\n",
       "      <td>1.696682e+00</td>\n",
       "      <td>1.007353e+00</td>\n",
       "      <td>2.819865e+00</td>\n",
       "      <td>1.261610e+00</td>\n",
       "      <td>1.033538e+01</td>\n",
       "      <td>2.484195e+00</td>\n",
       "      <td>3.417549e+00</td>\n",
       "      <td>3.007063e+00</td>\n",
       "      <td>2.157228e+01</td>\n",
       "      <td>...</td>\n",
       "      <td>7.512952e+00</td>\n",
       "      <td>4.984977e+00</td>\n",
       "      <td>1.604681e+01</td>\n",
       "      <td>3.893103e+00</td>\n",
       "      <td>5.423261e+00</td>\n",
       "      <td>2.928152e+00</td>\n",
       "      <td>1.604681e+01</td>\n",
       "      <td>2.271563e+01</td>\n",
       "      <td>5.785038e+00</td>\n",
       "      <td>1.416268e+00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows × 30 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                 0             1             2             3             4   \\\n",
       "count  5.170000e+02  5.170000e+02  5.170000e+02  5.170000e+02  5.170000e+02   \n",
       "mean  -4.874674e-17  5.110891e-17 -1.754024e-15  3.070830e-16  7.387171e-17   \n",
       "std    1.000969e+00  1.000969e+00  1.000969e+00  1.000969e+00  1.000969e+00   \n",
       "min   -1.317959e+00 -1.423121e+00 -1.304582e+01 -1.715608e+00 -2.179108e+00   \n",
       "25%   -1.089076e+00 -9.031536e-01 -8.063453e-02 -6.606652e-01 -4.448281e-01   \n",
       "50%    5.533922e-02  1.367805e-01  1.732292e-01 -4.020255e-02  4.691190e-01   \n",
       "75%    1.199754e+00  6.567476e-01  4.089598e-01  4.927389e-01  6.696628e-01   \n",
       "max    1.199754e+00  1.696682e+00  1.007353e+00  2.819865e+00  1.261610e+00   \n",
       "\n",
       "                 5             6             7             8             9   \\\n",
       "count  5.170000e+02  5.170000e+02  5.170000e+02  5.170000e+02  5.170000e+02   \n",
       "mean  -3.865380e-17  2.005703e-16  3.362881e-16 -2.676776e-16 -2.841054e-16   \n",
       "std    1.000969e+00  1.000969e+00  1.000969e+00  1.000969e+00  1.000969e+00   \n",
       "min   -1.980578e+00 -2.876943e+00 -1.796637e+00 -2.021098e+00 -7.326831e-02   \n",
       "25%   -5.535954e-01 -5.842379e-01 -6.924563e-01 -7.361236e-01 -7.326831e-02   \n",
       "50%   -1.364774e-01  7.082076e-02 -1.403660e-01 -9.833712e-03 -7.326831e-02   \n",
       "75%    3.904086e-01  6.741643e-01  5.344111e-01  4.929823e-01 -7.326831e-02   \n",
       "max    1.033538e+01  2.484195e+00  3.417549e+00  3.007063e+00  2.157228e+01   \n",
       "\n",
       "       ...            20            21            22            23  \\\n",
       "count  ...  5.170000e+02  5.170000e+02  5.170000e+02  5.170000e+02   \n",
       "mean   ...  7.179943e-16 -1.933764e-16 -2.260174e-17  1.352883e-17   \n",
       "std    ...  1.000969e+00  1.000969e+00  1.000969e+00  1.000969e+00   \n",
       "min    ... -1.331035e-01 -2.006027e-01 -6.231770e-02 -2.568645e-01   \n",
       "25%    ... -1.331035e-01 -2.006027e-01 -6.231770e-02 -2.568645e-01   \n",
       "50%    ... -1.331035e-01 -2.006027e-01 -6.231770e-02 -2.568645e-01   \n",
       "75%    ... -1.331035e-01 -2.006027e-01 -6.231770e-02 -2.568645e-01   \n",
       "max    ...  7.512952e+00  4.984977e+00  1.604681e+01  3.893103e+00   \n",
       "\n",
       "                 24            25            26            27            28  \\\n",
       "count  5.170000e+02  5.170000e+02  5.170000e+02  5.170000e+02  5.170000e+02   \n",
       "mean   1.169277e-16  2.265542e-16 -2.596515e-16  1.443075e-16  6.253326e-16   \n",
       "std    1.000969e+00  1.000969e+00  1.000969e+00  1.000969e+00  1.000969e+00   \n",
       "min   -1.843909e-01 -3.415123e-01 -6.231770e-02 -4.402255e-02 -1.728597e-01   \n",
       "25%   -1.843909e-01 -3.415123e-01 -6.231770e-02 -4.402255e-02 -1.728597e-01   \n",
       "50%   -1.843909e-01 -3.415123e-01 -6.231770e-02 -4.402255e-02 -1.728597e-01   \n",
       "75%   -1.843909e-01 -3.415123e-01 -6.231770e-02 -4.402255e-02 -1.728597e-01   \n",
       "max    5.423261e+00  2.928152e+00  1.604681e+01  2.271563e+01  5.785038e+00   \n",
       "\n",
       "                 29  \n",
       "count  5.170000e+02  \n",
       "mean   4.024290e-16  \n",
       "std    1.000969e+00  \n",
       "min   -7.060812e-01  \n",
       "25%   -7.060812e-01  \n",
       "50%   -7.060812e-01  \n",
       "75%    1.416268e+00  \n",
       "max    1.416268e+00  \n",
       "\n",
       "[8 rows x 30 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(X_standardized).describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model():\n",
    "    model = Sequential()\n",
    "    model.add(Dense(12, input_dim=30, kernel_initializer='uniform', activation='relu'))\n",
    "    model.add(Dense(8, kernel_initializer='uniform', activation='relu'))\n",
    "    model.add(Dense(1, kernel_initializer='uniform', activation='sigmoid'))\\\n",
    "    \n",
    "    adam=Adam(lr=0.01)\n",
    "    model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.optimizers import Adam\n",
    "import tensorflow as tf\n",
    "tf.compat.v1.disable_eager_execution ()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 9 candidates, totalling 45 fits\n",
      "[CV] batch_size=10, epochs=10 ........................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "C:\\Users\\Acer\\anaconda3\\lib\\site-packages\\keras\\engine\\training.py:2401: UserWarning: `Model.state_updates` will be removed in a future version. This property should not be used in TensorFlow 2.0, as `updates` are applied automatically.\n",
      "  warnings.warn('`Model.state_updates` will be removed in a future version. '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] ............ batch_size=10, epochs=10, score=1.000, total=   4.0s\n",
      "[CV] batch_size=10, epochs=10 ........................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    3.9s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] ............ batch_size=10, epochs=10, score=0.750, total=   2.1s\n",
      "[CV] batch_size=10, epochs=10 ........................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    6.0s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] ............ batch_size=10, epochs=10, score=0.524, total=   2.1s\n",
      "[CV] batch_size=10, epochs=10 ........................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   3 out of   3 | elapsed:    8.1s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] ............ batch_size=10, epochs=10, score=0.699, total=   2.1s\n",
      "[CV] batch_size=10, epochs=10 ........................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   4 out of   4 | elapsed:   10.2s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] ............ batch_size=10, epochs=10, score=0.699, total=   2.1s\n",
      "[CV] batch_size=10, epochs=50 ........................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:   12.4s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] ............ batch_size=10, epochs=50, score=1.000, total=   4.9s\n",
      "[CV] batch_size=10, epochs=50 ........................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   6 out of   6 | elapsed:   17.2s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] ............ batch_size=10, epochs=50, score=0.923, total=   5.0s\n",
      "[CV] batch_size=10, epochs=50 ........................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   7 out of   7 | elapsed:   22.2s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] ............ batch_size=10, epochs=50, score=0.951, total=   5.4s\n",
      "[CV] batch_size=10, epochs=50 ........................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   8 out of   8 | elapsed:   27.7s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] ............ batch_size=10, epochs=50, score=0.893, total=   5.3s\n",
      "[CV] batch_size=10, epochs=50 ........................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   9 out of   9 | elapsed:   32.9s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] ............ batch_size=10, epochs=50, score=0.893, total=   5.9s\n",
      "[CV] batch_size=10, epochs=100 .......................................\n",
      "[CV] ........... batch_size=10, epochs=100, score=1.000, total=   9.2s\n",
      "[CV] batch_size=10, epochs=100 .......................................\n",
      "[CV] ........... batch_size=10, epochs=100, score=0.875, total=   9.7s\n",
      "[CV] batch_size=10, epochs=100 .......................................\n",
      "[CV] ........... batch_size=10, epochs=100, score=0.903, total=  10.3s\n",
      "[CV] batch_size=10, epochs=100 .......................................\n",
      "[CV] ........... batch_size=10, epochs=100, score=0.903, total=  10.5s\n",
      "[CV] batch_size=10, epochs=100 .......................................\n",
      "[CV] ........... batch_size=10, epochs=100, score=0.883, total=  11.7s\n",
      "[CV] batch_size=20, epochs=10 ........................................\n",
      "[CV] ............ batch_size=20, epochs=10, score=1.000, total=   3.2s\n",
      "[CV] batch_size=20, epochs=10 ........................................\n",
      "[CV] ............ batch_size=20, epochs=10, score=0.750, total=   3.1s\n",
      "[CV] batch_size=20, epochs=10 ........................................\n",
      "[CV] ............ batch_size=20, epochs=10, score=0.524, total=   2.9s\n",
      "[CV] batch_size=20, epochs=10 ........................................\n",
      "[CV] ............ batch_size=20, epochs=10, score=0.680, total=   3.1s\n",
      "[CV] batch_size=20, epochs=10 ........................................\n",
      "[CV] ............ batch_size=20, epochs=10, score=0.699, total=   3.1s\n",
      "[CV] batch_size=20, epochs=50 ........................................\n",
      "[CV] ............ batch_size=20, epochs=50, score=0.990, total=   5.1s\n",
      "[CV] batch_size=20, epochs=50 ........................................\n",
      "[CV] ............ batch_size=20, epochs=50, score=0.788, total=   5.0s\n",
      "[CV] batch_size=20, epochs=50 ........................................\n",
      "[CV] ............ batch_size=20, epochs=50, score=0.748, total=   5.1s\n",
      "[CV] batch_size=20, epochs=50 ........................................\n",
      "[CV] ............ batch_size=20, epochs=50, score=0.835, total=   5.2s\n",
      "[CV] batch_size=20, epochs=50 ........................................\n",
      "[CV] ............ batch_size=20, epochs=50, score=0.874, total=   5.2s\n",
      "[CV] batch_size=20, epochs=100 .......................................\n",
      "[CV] ........... batch_size=20, epochs=100, score=0.990, total=   8.0s\n",
      "[CV] batch_size=20, epochs=100 .......................................\n",
      "[CV] ........... batch_size=20, epochs=100, score=0.837, total=   8.7s\n",
      "[CV] batch_size=20, epochs=100 .......................................\n",
      "[CV] ........... batch_size=20, epochs=100, score=0.903, total=   9.7s\n",
      "[CV] batch_size=20, epochs=100 .......................................\n",
      "[CV] ........... batch_size=20, epochs=100, score=0.903, total=   9.0s\n",
      "[CV] batch_size=20, epochs=100 .......................................\n",
      "[CV] ........... batch_size=20, epochs=100, score=0.883, total=   9.2s\n",
      "[CV] batch_size=40, epochs=10 ........................................\n",
      "[CV] ............ batch_size=40, epochs=10, score=1.000, total=   3.7s\n",
      "[CV] batch_size=40, epochs=10 ........................................\n",
      "[CV] ............ batch_size=40, epochs=10, score=0.750, total=   3.8s\n",
      "[CV] batch_size=40, epochs=10 ........................................\n",
      "[CV] ............ batch_size=40, epochs=10, score=0.524, total=   4.0s\n",
      "[CV] batch_size=40, epochs=10 ........................................\n",
      "[CV] ............ batch_size=40, epochs=10, score=0.680, total=   4.0s\n",
      "[CV] batch_size=40, epochs=10 ........................................\n",
      "[CV] ............ batch_size=40, epochs=10, score=0.699, total=   4.3s\n",
      "[CV] batch_size=40, epochs=50 ........................................\n",
      "[CV] ............ batch_size=40, epochs=50, score=0.981, total=   6.5s\n",
      "[CV] batch_size=40, epochs=50 ........................................\n",
      "[CV] ............ batch_size=40, epochs=50, score=0.750, total=   5.9s\n",
      "[CV] batch_size=40, epochs=50 ........................................\n",
      "[CV] ............ batch_size=40, epochs=50, score=0.728, total=   6.0s\n",
      "[CV] batch_size=40, epochs=50 ........................................\n",
      "[CV] ............ batch_size=40, epochs=50, score=0.738, total=   6.1s\n",
      "[CV] batch_size=40, epochs=50 ........................................\n",
      "[CV] ............ batch_size=40, epochs=50, score=0.748, total=   6.2s\n",
      "[CV] batch_size=40, epochs=100 .......................................\n",
      "[CV] ........... batch_size=40, epochs=100, score=1.000, total=   8.1s\n",
      "[CV] batch_size=40, epochs=100 .......................................\n",
      "[CV] ........... batch_size=40, epochs=100, score=0.817, total=   7.6s\n",
      "[CV] batch_size=40, epochs=100 .......................................\n",
      "[CV] ........... batch_size=40, epochs=100, score=0.835, total=   7.6s\n",
      "[CV] batch_size=40, epochs=100 .......................................\n",
      "[CV] ........... batch_size=40, epochs=100, score=0.854, total=   8.2s\n",
      "[CV] batch_size=40, epochs=100 .......................................\n",
      "[CV] ........... batch_size=40, epochs=100, score=0.874, total=   8.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  45 out of  45 | elapsed:  4.4min finished\n"
     ]
    }
   ],
   "source": [
    "model = KerasClassifier(build_fn = create_model,verbose = 0)\n",
    "# Define the grid search parameters\n",
    "batch_size = [10,20,40]\n",
    "epochs = [10,50,100]\n",
    "# Make a dictionary of the grid search parameters\n",
    "param_grid = dict(batch_size = batch_size,epochs = epochs)\n",
    "# Build and fit the GridSearchCV\n",
    "grid = GridSearchCV(estimator = model,param_grid = param_grid,cv = KFold(),verbose = 10)\n",
    "grid_result = grid.fit(X_standardized,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best : 0.9321881890296936, using {'batch_size': 10, 'epochs': 50}\n",
      "0.7344660282135009,0.1532597362499129 with: {'batch_size': 10, 'epochs': 10}\n",
      "0.9321881890296936,0.04023002331954689 with: {'batch_size': 10, 'epochs': 50}\n",
      "0.9128640770912171,0.04491537439006765 with: {'batch_size': 10, 'epochs': 100}\n",
      "0.7305825233459473,0.15435061319000673 with: {'batch_size': 20, 'epochs': 10}\n",
      "0.8470313787460327,0.08334786874150642 with: {'batch_size': 20, 'epochs': 50}\n",
      "0.9032486915588379,0.04986654167614934 with: {'batch_size': 20, 'epochs': 100}\n",
      "0.7305825233459473,0.15435061319000673 with: {'batch_size': 40, 'epochs': 10}\n",
      "0.7888722896575928,0.09625956472530685 with: {'batch_size': 40, 'epochs': 50}\n",
      "0.8760828971862793,0.06477427969143784 with: {'batch_size': 40, 'epochs': 100}\n"
     ]
    }
   ],
   "source": [
    "print('Best : {}, using {}'.format(grid_result.best_score_,grid_result.best_params_))\n",
    "means = grid_result.cv_results_['mean_test_score']\n",
    "stds = grid_result.cv_results_['std_test_score']\n",
    "params = grid_result.cv_results_['params']\n",
    "for mean, stdev, param in zip(means, stds, params):\n",
    "  print('{},{} with: {}'.format(mean, stdev, param))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model(activation_function,init):\n",
    "    model = Sequential()\n",
    "    model.add(Dense(8,input_dim = 30,kernel_initializer = init,activation = activation_function))\n",
    "    model.add(Dropout(0.1))\n",
    "    model.add(Dense(4,input_dim = 30,kernel_initializer = init,activation = activation_function))\n",
    "    model.add(Dropout(0.1))\n",
    "    model.add(Dense(1,activation = 'sigmoid'))\n",
    "    \n",
    "    adam = Adam(lr = 0.001)\n",
    "    model.compile(loss = 'binary_crossentropy',optimizer = 'adam',metrics = ['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 12 candidates, totalling 60 fits\n",
      "[CV] activation_function=softmax, init=uniform .......................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  activation_function=softmax, init=uniform, score=0.000, total=   6.2s\n",
      "[CV] activation_function=softmax, init=uniform .......................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    6.1s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  activation_function=softmax, init=uniform, score=0.750, total=   5.5s\n",
      "[CV] activation_function=softmax, init=uniform .......................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:   11.6s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  activation_function=softmax, init=uniform, score=0.476, total=   6.2s\n",
      "[CV] activation_function=softmax, init=uniform .......................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   3 out of   3 | elapsed:   17.8s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  activation_function=softmax, init=uniform, score=0.680, total=   6.3s\n",
      "[CV] activation_function=softmax, init=uniform .......................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   4 out of   4 | elapsed:   24.1s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  activation_function=softmax, init=uniform, score=0.699, total=   6.3s\n",
      "[CV] activation_function=softmax, init=normal ........................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:   30.4s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  activation_function=softmax, init=normal, score=0.000, total=   6.2s\n",
      "[CV] activation_function=softmax, init=normal ........................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   6 out of   6 | elapsed:   36.6s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  activation_function=softmax, init=normal, score=0.750, total=   6.5s\n",
      "[CV] activation_function=softmax, init=normal ........................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   7 out of   7 | elapsed:   43.1s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  activation_function=softmax, init=normal, score=0.476, total=   6.7s\n",
      "[CV] activation_function=softmax, init=normal ........................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   8 out of   8 | elapsed:   49.8s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  activation_function=softmax, init=normal, score=0.680, total=   6.9s\n",
      "[CV] activation_function=softmax, init=normal ........................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   9 out of   9 | elapsed:   56.7s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  activation_function=softmax, init=normal, score=0.699, total=   7.0s\n",
      "[CV] activation_function=softmax, init=zero ..........................\n",
      "[CV]  activation_function=softmax, init=zero, score=0.000, total=   7.1s\n",
      "[CV] activation_function=softmax, init=zero ..........................\n",
      "[CV]  activation_function=softmax, init=zero, score=0.250, total=   7.7s\n",
      "[CV] activation_function=softmax, init=zero ..........................\n",
      "[CV]  activation_function=softmax, init=zero, score=0.524, total=   8.1s\n",
      "[CV] activation_function=softmax, init=zero ..........................\n",
      "[CV]  activation_function=softmax, init=zero, score=0.680, total=   7.7s\n",
      "[CV] activation_function=softmax, init=zero ..........................\n",
      "[CV]  activation_function=softmax, init=zero, score=0.699, total=   7.9s\n",
      "[CV] activation_function=relu, init=uniform ..........................\n",
      "[CV]  activation_function=relu, init=uniform, score=1.000, total=   8.0s\n",
      "[CV] activation_function=relu, init=uniform ..........................\n",
      "[CV]  activation_function=relu, init=uniform, score=0.750, total=   8.3s\n",
      "[CV] activation_function=relu, init=uniform ..........................\n",
      "[CV]  activation_function=relu, init=uniform, score=0.524, total=   8.6s\n",
      "[CV] activation_function=relu, init=uniform ..........................\n",
      "[CV]  activation_function=relu, init=uniform, score=0.680, total=   8.7s\n",
      "[CV] activation_function=relu, init=uniform ..........................\n",
      "[CV]  activation_function=relu, init=uniform, score=0.699, total=   9.0s\n",
      "[CV] activation_function=relu, init=normal ...........................\n",
      "[CV]  activation_function=relu, init=normal, score=1.000, total=   9.2s\n",
      "[CV] activation_function=relu, init=normal ...........................\n",
      "[CV]  activation_function=relu, init=normal, score=0.750, total=   9.4s\n",
      "[CV] activation_function=relu, init=normal ...........................\n",
      "[CV]  activation_function=relu, init=normal, score=0.524, total=   9.5s\n",
      "[CV] activation_function=relu, init=normal ...........................\n",
      "[CV]  activation_function=relu, init=normal, score=0.680, total=   9.6s\n",
      "[CV] activation_function=relu, init=normal ...........................\n",
      "[CV]  activation_function=relu, init=normal, score=0.699, total=   9.9s\n",
      "[CV] activation_function=relu, init=zero .............................\n",
      "[CV] . activation_function=relu, init=zero, score=1.000, total=   9.9s\n",
      "[CV] activation_function=relu, init=zero .............................\n",
      "[CV] . activation_function=relu, init=zero, score=0.750, total=  10.0s\n",
      "[CV] activation_function=relu, init=zero .............................\n",
      "[CV] . activation_function=relu, init=zero, score=0.524, total=  10.4s\n",
      "[CV] activation_function=relu, init=zero .............................\n",
      "[CV] . activation_function=relu, init=zero, score=0.680, total=  10.6s\n",
      "[CV] activation_function=relu, init=zero .............................\n",
      "[CV] . activation_function=relu, init=zero, score=0.699, total=  10.5s\n",
      "[CV] activation_function=tanh, init=uniform ..........................\n",
      "[CV]  activation_function=tanh, init=uniform, score=0.971, total=  10.8s\n",
      "[CV] activation_function=tanh, init=uniform ..........................\n",
      "[CV]  activation_function=tanh, init=uniform, score=0.750, total=  11.7s\n",
      "[CV] activation_function=tanh, init=uniform ..........................\n",
      "[CV]  activation_function=tanh, init=uniform, score=0.612, total=  11.6s\n",
      "[CV] activation_function=tanh, init=uniform ..........................\n",
      "[CV]  activation_function=tanh, init=uniform, score=0.689, total=  11.7s\n",
      "[CV] activation_function=tanh, init=uniform ..........................\n",
      "[CV]  activation_function=tanh, init=uniform, score=0.699, total=  13.2s\n",
      "[CV] activation_function=tanh, init=normal ...........................\n",
      "[CV]  activation_function=tanh, init=normal, score=1.000, total=  11.7s\n",
      "[CV] activation_function=tanh, init=normal ...........................\n",
      "[CV]  activation_function=tanh, init=normal, score=0.750, total=  12.2s\n",
      "[CV] activation_function=tanh, init=normal ...........................\n",
      "[CV]  activation_function=tanh, init=normal, score=0.621, total=  12.2s\n",
      "[CV] activation_function=tanh, init=normal ...........................\n",
      "[CV]  activation_function=tanh, init=normal, score=0.680, total=  12.3s\n",
      "[CV] activation_function=tanh, init=normal ...........................\n",
      "[CV]  activation_function=tanh, init=normal, score=0.718, total=  12.6s\n",
      "[CV] activation_function=tanh, init=zero .............................\n",
      "[CV] . activation_function=tanh, init=zero, score=1.000, total=  12.7s\n",
      "[CV] activation_function=tanh, init=zero .............................\n",
      "[CV] . activation_function=tanh, init=zero, score=0.750, total=  12.9s\n",
      "[CV] activation_function=tanh, init=zero .............................\n",
      "[CV] . activation_function=tanh, init=zero, score=0.524, total=  13.2s\n",
      "[CV] activation_function=tanh, init=zero .............................\n",
      "[CV] . activation_function=tanh, init=zero, score=0.680, total=  13.3s\n",
      "[CV] activation_function=tanh, init=zero .............................\n",
      "[CV] . activation_function=tanh, init=zero, score=0.699, total=  13.8s\n",
      "[CV] activation_function=linear, init=uniform ........................\n",
      "[CV]  activation_function=linear, init=uniform, score=0.981, total=  13.8s\n",
      "[CV] activation_function=linear, init=uniform ........................\n",
      "[CV]  activation_function=linear, init=uniform, score=0.740, total=  13.7s\n",
      "[CV] activation_function=linear, init=uniform ........................\n",
      "[CV]  activation_function=linear, init=uniform, score=0.592, total=  13.8s\n",
      "[CV] activation_function=linear, init=uniform ........................\n",
      "[CV]  activation_function=linear, init=uniform, score=0.689, total=  14.6s\n",
      "[CV] activation_function=linear, init=uniform ........................\n",
      "[CV]  activation_function=linear, init=uniform, score=0.718, total=  14.8s\n",
      "[CV] activation_function=linear, init=normal .........................\n",
      "[CV]  activation_function=linear, init=normal, score=0.933, total=  14.9s\n",
      "[CV] activation_function=linear, init=normal .........................\n",
      "[CV]  activation_function=linear, init=normal, score=0.750, total=  14.9s\n",
      "[CV] activation_function=linear, init=normal .........................\n",
      "[CV]  activation_function=linear, init=normal, score=0.573, total=  15.8s\n",
      "[CV] activation_function=linear, init=normal .........................\n",
      "[CV]  activation_function=linear, init=normal, score=0.680, total=  15.7s\n",
      "[CV] activation_function=linear, init=normal .........................\n",
      "[CV]  activation_function=linear, init=normal, score=0.699, total=  15.8s\n",
      "[CV] activation_function=linear, init=zero ...........................\n",
      "[CV]  activation_function=linear, init=zero, score=1.000, total=  15.8s\n",
      "[CV] activation_function=linear, init=zero ...........................\n",
      "[CV]  activation_function=linear, init=zero, score=0.750, total=  16.0s\n",
      "[CV] activation_function=linear, init=zero ...........................\n",
      "[CV]  activation_function=linear, init=zero, score=0.524, total=  16.5s\n",
      "[CV] activation_function=linear, init=zero ...........................\n",
      "[CV]  activation_function=linear, init=zero, score=0.680, total=  16.7s\n",
      "[CV] activation_function=linear, init=zero ...........................\n",
      "[CV]  activation_function=linear, init=zero, score=0.699, total=  16.3s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  60 out of  60 | elapsed: 11.0min finished\n"
     ]
    }
   ],
   "source": [
    "model = KerasClassifier(build_fn = create_model,verbose = 0,batch_size = 40,epochs = 10)\n",
    "\n",
    "# Define the grid search parameters\n",
    "activation_function = ['softmax','relu','tanh','linear']\n",
    "init = ['uniform','normal','zero']\n",
    "\n",
    "# Make a dictionary of the grid search parameters\n",
    "param_grids = dict(activation_function = activation_function,init = init)\n",
    "\n",
    "# Build and fit the GridSearchCV\n",
    "\n",
    "grid = GridSearchCV(estimator = model,param_grid = param_grids,cv = KFold(),verbose = 10)\n",
    "grid_result = grid.fit(X_standardized,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best : 0.7538834929466247, using {'activation_function': 'tanh', 'init': 'normal'}\n",
      "0.5208737850189209,0.2766888088877092 with: {'activation_function': 'softmax', 'init': 'uniform'}\n",
      "0.5208737850189209,0.2766888088877092 with: {'activation_function': 'softmax', 'init': 'normal'}\n",
      "0.43058252334594727,0.2686514950632128 with: {'activation_function': 'softmax', 'init': 'zero'}\n",
      "0.7305825233459473,0.15435061319000673 with: {'activation_function': 'relu', 'init': 'uniform'}\n",
      "0.7305825233459473,0.15435061319000673 with: {'activation_function': 'relu', 'init': 'normal'}\n",
      "0.7305825233459473,0.15435061319000673 with: {'activation_function': 'relu', 'init': 'zero'}\n",
      "0.7442307710647583,0.12178936277756071 with: {'activation_function': 'tanh', 'init': 'uniform'}\n",
      "0.7538834929466247,0.13032511669013647 with: {'activation_function': 'tanh', 'init': 'normal'}\n",
      "0.7305825233459473,0.15435061319000673 with: {'activation_function': 'tanh', 'init': 'zero'}\n",
      "0.7442307710647583,0.1286456561112577 with: {'activation_function': 'linear', 'init': 'uniform'}\n",
      "0.726829719543457,0.11801614147474013 with: {'activation_function': 'linear', 'init': 'normal'}\n",
      "0.7305825233459473,0.15435061319000673 with: {'activation_function': 'linear', 'init': 'zero'}\n"
     ]
    }
   ],
   "source": [
    "print('Best : {}, using {}'.format(grid_result.best_score_,grid_result.best_params_))\n",
    "means = grid_result.cv_results_['mean_test_score']\n",
    "stds = grid_result.cv_results_['std_test_score']\n",
    "params = grid_result.cv_results_['params']\n",
    "for mean, stdev, param in zip(means, stds, params):\n",
    "  print('{},{} with: {}'.format(mean, stdev, param))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model(neuron1,neuron2):\n",
    "    model = Sequential()\n",
    "    model.add(Dense(neuron1,input_dim = 30,kernel_initializer = 'uniform',activation = 'tanh'))\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(Dense(neuron2,input_dim = neuron1,kernel_initializer = 'uniform',activation = 'tanh'))\n",
    "    model.add(Dropout(0.1))\n",
    "    model.add(Dense(1,activation = 'sigmoid'))\n",
    "    \n",
    "    adam = Adam(lr = 0.001)\n",
    "    model.compile(loss = 'binary_crossentropy',optimizer = 'adam',metrics = ['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 9 candidates, totalling 45 fits\n",
      "[CV] neuron1=4, neuron2=2 ............................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "C:\\Users\\Acer\\anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\optimizer_v2\\optimizer_v2.py:374: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Acer\\anaconda3\\lib\\site-packages\\keras\\engine\\training.py:2401: UserWarning: `Model.state_updates` will be removed in a future version. This property should not be used in TensorFlow 2.0, as `updates` are applied automatically.\n",
      "  warnings.warn('`Model.state_updates` will be removed in a future version. '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] ................ neuron1=4, neuron2=2, score=1.000, total=  17.4s\n",
      "[CV] neuron1=4, neuron2=2 ............................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:   17.3s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] ................ neuron1=4, neuron2=2, score=0.750, total=  18.9s\n",
      "[CV] neuron1=4, neuron2=2 ............................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:   36.3s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] ................ neuron1=4, neuron2=2, score=0.592, total=  16.9s\n",
      "[CV] neuron1=4, neuron2=2 ............................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   3 out of   3 | elapsed:   53.2s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] ................ neuron1=4, neuron2=2, score=0.680, total=  17.2s\n",
      "[CV] neuron1=4, neuron2=2 ............................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   4 out of   4 | elapsed:  1.2min remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] ................ neuron1=4, neuron2=2, score=0.709, total=  17.1s\n",
      "[CV] neuron1=4, neuron2=4 ............................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:  1.5min remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] ................ neuron1=4, neuron2=4, score=0.933, total=  17.2s\n",
      "[CV] neuron1=4, neuron2=4 ............................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   6 out of   6 | elapsed:  1.7min remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] ................ neuron1=4, neuron2=4, score=0.750, total=  17.5s\n",
      "[CV] neuron1=4, neuron2=4 ............................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   7 out of   7 | elapsed:  2.0min remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] ................ neuron1=4, neuron2=4, score=0.563, total=  18.2s\n",
      "[CV] neuron1=4, neuron2=4 ............................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   8 out of   8 | elapsed:  2.3min remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] ................ neuron1=4, neuron2=4, score=0.680, total=  18.2s\n",
      "[CV] neuron1=4, neuron2=4 ............................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   9 out of   9 | elapsed:  2.6min remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] ................ neuron1=4, neuron2=4, score=0.709, total=  18.8s\n",
      "[CV] neuron1=4, neuron2=8 ............................................\n",
      "[CV] ................ neuron1=4, neuron2=8, score=0.962, total=  18.9s\n",
      "[CV] neuron1=4, neuron2=8 ............................................\n",
      "[CV] ................ neuron1=4, neuron2=8, score=0.750, total=  19.3s\n",
      "[CV] neuron1=4, neuron2=8 ............................................\n",
      "[CV] ................ neuron1=4, neuron2=8, score=0.592, total=  19.6s\n",
      "[CV] neuron1=4, neuron2=8 ............................................\n",
      "[CV] ................ neuron1=4, neuron2=8, score=0.680, total=  20.6s\n",
      "[CV] neuron1=4, neuron2=8 ............................................\n",
      "[CV] ................ neuron1=4, neuron2=8, score=0.718, total=  19.7s\n",
      "[CV] neuron1=8, neuron2=2 ............................................\n",
      "[CV] ................ neuron1=8, neuron2=2, score=0.962, total=  20.0s\n",
      "[CV] neuron1=8, neuron2=2 ............................................\n",
      "[CV] ................ neuron1=8, neuron2=2, score=0.750, total=  20.0s\n",
      "[CV] neuron1=8, neuron2=2 ............................................\n",
      "[CV] ................ neuron1=8, neuron2=2, score=0.583, total=  20.6s\n",
      "[CV] neuron1=8, neuron2=2 ............................................\n",
      "[CV] ................ neuron1=8, neuron2=2, score=0.680, total=  20.7s\n",
      "[CV] neuron1=8, neuron2=2 ............................................\n",
      "[CV] ................ neuron1=8, neuron2=2, score=0.699, total=  21.5s\n",
      "[CV] neuron1=8, neuron2=4 ............................................\n",
      "[CV] ................ neuron1=8, neuron2=4, score=1.000, total=  20.8s\n",
      "[CV] neuron1=8, neuron2=4 ............................................\n",
      "[CV] ................ neuron1=8, neuron2=4, score=0.750, total=  20.9s\n",
      "[CV] neuron1=8, neuron2=4 ............................................\n",
      "[CV] ................ neuron1=8, neuron2=4, score=0.660, total=  21.3s\n",
      "[CV] neuron1=8, neuron2=4 ............................................\n",
      "[CV] ................ neuron1=8, neuron2=4, score=0.680, total=  21.5s\n",
      "[CV] neuron1=8, neuron2=4 ............................................\n",
      "[CV] ................ neuron1=8, neuron2=4, score=0.699, total=  24.9s\n",
      "[CV] neuron1=8, neuron2=8 ............................................\n",
      "[CV] ................ neuron1=8, neuron2=8, score=1.000, total=  22.0s\n",
      "[CV] neuron1=8, neuron2=8 ............................................\n",
      "[CV] ................ neuron1=8, neuron2=8, score=0.750, total=  23.9s\n",
      "[CV] neuron1=8, neuron2=8 ............................................\n",
      "[CV] ................ neuron1=8, neuron2=8, score=0.602, total=  22.7s\n",
      "[CV] neuron1=8, neuron2=8 ............................................\n",
      "[CV] ................ neuron1=8, neuron2=8, score=0.689, total=  22.9s\n",
      "[CV] neuron1=8, neuron2=8 ............................................\n",
      "[CV] ................ neuron1=8, neuron2=8, score=0.699, total=  23.5s\n",
      "[CV] neuron1=16, neuron2=2 ...........................................\n",
      "[CV] ............... neuron1=16, neuron2=2, score=0.981, total=  24.5s\n",
      "[CV] neuron1=16, neuron2=2 ...........................................\n",
      "[CV] ............... neuron1=16, neuron2=2, score=0.750, total=  26.0s\n",
      "[CV] neuron1=16, neuron2=2 ...........................................\n",
      "[CV] ............... neuron1=16, neuron2=2, score=0.602, total=  28.8s\n",
      "[CV] neuron1=16, neuron2=2 ...........................................\n",
      "[CV] ............... neuron1=16, neuron2=2, score=0.699, total=  29.1s\n",
      "[CV] neuron1=16, neuron2=2 ...........................................\n",
      "[CV] ............... neuron1=16, neuron2=2, score=0.709, total=  24.6s\n",
      "[CV] neuron1=16, neuron2=4 ...........................................\n",
      "[CV] ............... neuron1=16, neuron2=4, score=0.942, total=  25.8s\n",
      "[CV] neuron1=16, neuron2=4 ...........................................\n",
      "[CV] ............... neuron1=16, neuron2=4, score=0.750, total= 1.5min\n",
      "[CV] neuron1=16, neuron2=4 ...........................................\n",
      "[CV] ............... neuron1=16, neuron2=4, score=0.631, total=  29.1s\n",
      "[CV] neuron1=16, neuron2=4 ...........................................\n",
      "[CV] ............... neuron1=16, neuron2=4, score=0.699, total=  27.5s\n",
      "[CV] neuron1=16, neuron2=4 ...........................................\n",
      "[CV] ............... neuron1=16, neuron2=4, score=0.680, total=  28.7s\n",
      "[CV] neuron1=16, neuron2=8 ...........................................\n",
      "[CV] ............... neuron1=16, neuron2=8, score=0.952, total=  27.2s\n",
      "[CV] neuron1=16, neuron2=8 ...........................................\n",
      "[CV] ............... neuron1=16, neuron2=8, score=0.750, total=  27.9s\n",
      "[CV] neuron1=16, neuron2=8 ...........................................\n",
      "[CV] ............... neuron1=16, neuron2=8, score=0.680, total=  29.3s\n",
      "[CV] neuron1=16, neuron2=8 ...........................................\n",
      "[CV] ............... neuron1=16, neuron2=8, score=0.699, total=  28.2s\n",
      "[CV] neuron1=16, neuron2=8 ...........................................\n",
      "[CV] ............... neuron1=16, neuron2=8, score=0.709, total=  26.3s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  45 out of  45 | elapsed: 17.9min finished\n"
     ]
    }
   ],
   "source": [
    "model = KerasClassifier(build_fn = create_model,verbose = 0,batch_size = 40,epochs = 10)\n",
    "\n",
    "# Define the grid search parameters\n",
    "\n",
    "neuron1 = [4,8,16]\n",
    "neuron2 = [2,4,8]\n",
    "\n",
    "# Make a dictionary of the grid search parameters\n",
    "\n",
    "param_grids = dict(neuron1 = neuron1,neuron2 = neuron2)\n",
    "\n",
    "# Build and fit the GridSearchCV\n",
    "\n",
    "grid = GridSearchCV(estimator = model,param_grid = param_grids,cv = KFold(),verbose = 10)\n",
    "grid_result = grid.fit(X_standardized,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best : 0.7578603386878967, using {'neuron1': 16, 'neuron2': 8}\n",
      "0.7461164951324463,0.13709274680470043 with: {'neuron1': 4, 'neuron2': 2}\n",
      "0.7268297076225281,0.12023171492798866 with: {'neuron1': 4, 'neuron2': 4}\n",
      "0.7403659343719482,0.1225765054289748 with: {'neuron1': 4, 'neuron2': 8}\n",
      "0.7345407009124756,0.1258206827316059 with: {'neuron1': 8, 'neuron2': 2}\n",
      "0.7577669858932495,0.1247525632414666 with: {'neuron1': 8, 'neuron2': 4}\n",
      "0.7480582594871521,0.13467177341546857 with: {'neuron1': 8, 'neuron2': 8}\n",
      "0.7480955958366394,0.12606199402401552 with: {'neuron1': 16, 'neuron2': 2}\n",
      "0.7404032826423645,0.10790658821769852 with: {'neuron1': 16, 'neuron2': 4}\n",
      "0.7578603386878967,0.09971872331325274 with: {'neuron1': 16, 'neuron2': 8}\n"
     ]
    }
   ],
   "source": [
    "print('Best : {}, using {}'.format(grid_result.best_score_,grid_result.best_params_))\n",
    "means = grid_result.cv_results_['mean_test_score']\n",
    "stds = grid_result.cv_results_['std_test_score']\n",
    "params = grid_result.cv_results_['params']\n",
    "for mean, stdev, param in zip(means, stds, params):\n",
    "  print('{},{} with: {}'.format(mean, stdev, param))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "\n",
    "def create_model():\n",
    "    model = Sequential()\n",
    "    model.add(Dense(16,input_dim = 30,kernel_initializer = 'normal',activation = 'linear'))\n",
    "    model.add(Dropout(0.1))\n",
    "    model.add(Dense(8,input_dim = 30,kernel_initializer = 'normal',activation = 'linear'))\n",
    "    model.add(Dropout(0.1))\n",
    "    model.add(Dense(1,activation = 'linear'))\n",
    "    \n",
    "    adam = Adam(lr = 0.01) #sgd = SGD(lr=learning_rate, momentum=momentum, decay=decay_rate, nesterov=False)\n",
    "    model.compile(loss = 'binary_crossentropy',optimizer = 'adam',metrics = ['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Acer\\anaconda3\\lib\\site-packages\\keras\\engine\\sequential.py:450: UserWarning: `model.predict_classes()` is deprecated and will be removed after 2021-01-01. Please use instead:* `np.argmax(model.predict(x), axis=-1)`,   if your model does multi-class classification   (e.g. if it uses a `softmax` last-layer activation).* `(model.predict(x) > 0.5).astype(\"int32\")`,   if your model does binary classification   (e.g. if it uses a `sigmoid` last-layer activation).\n",
      "  warnings.warn('`model.predict_classes()` is deprecated and '\n",
      "C:\\Users\\Acer\\anaconda3\\lib\\site-packages\\keras\\engine\\training.py:2401: UserWarning: `Model.state_updates` will be removed in a future version. This property should not be used in TensorFlow 2.0, as `updates` are applied automatically.\n",
      "  warnings.warn('`Model.state_updates` will be removed in a future version. '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8646034816247582\n"
     ]
    }
   ],
   "source": [
    "model = KerasClassifier(build_fn = create_model,verbose = 0,batch_size = 40,epochs = 100)\n",
    "\n",
    "# Fitting the model\n",
    "\n",
    "model.fit(X_standardized,y)\n",
    "\n",
    "# Predicting using trained model\n",
    "\n",
    "y_predict = model.predict(X_standardized)\n",
    "\n",
    "# Printing the metrics\n",
    "print(accuracy_score(y,y_predict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
